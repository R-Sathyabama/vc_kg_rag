# ğŸš€ Hybrid RAG Q&A System - Production Version

## ğŸ“‹ Overview

A production-ready **Hybrid Retrieval-Augmented Generation (RAG)** system that intelligently combines:
- **Vector Search** (semantic similarity)
- **Knowledge Graph** (entity relationships)

**Key Features:**
âœ… Clean, minimal UI for end users
âœ… Verbose terminal logging for developers/demos
âœ… Supports PDFs and Images (with OCR)
âœ… Advanced RAG techniques (Fusion, Adaptive, Corrective)
âœ… Knowledge graph entity extraction
âœ… Answer limited to 1000 tokens (concise responses)
âœ… No hardcoded values - configurable via config.py

---

## ğŸ¯ Quick Start (3 Steps)

### 1. Install Dependencies

```bash
# Install Tesseract OCR first
# Ubuntu/Debian:
sudo apt-get install tesseract-ocr poppler-utils

# macOS:
brew install tesseract poppler

# Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki

# Install Python packages
pip install -r requirements.txt
```

### 2. Set API Key

```bash
# Option A: Environment variable
export OPENAI_API_KEY="sk-your-key-here"

# Option B: Enter in UI sidebar when running
```

### 3. Run Application

```bash
streamlit run app_clean.py
```

Opens at: `http://localhost:8501`

---

## ğŸ“ File Structure

```
hybrid-rag-app/
â”œâ”€â”€ app_clean.py              â­ Main application (clean UI)
â”œâ”€â”€ hybrid_rag.py             Core hybrid engine
â”œâ”€â”€ vector_store.py           Vector search + RAG techniques
â”œâ”€â”€ knowledge_graph.py        Entity extraction & graph
â”œâ”€â”€ document_processor.py     PDF/Image processing
â”œâ”€â”€ config.py                 âš™ï¸ Configuration settings
â”œâ”€â”€ requirements.txt          Dependencies
â”‚
â”œâ”€â”€ SETUP.md                  Setup guide
â”œâ”€â”€ CLEAN_UI_README.md        This version's features
â”œâ”€â”€ TERMINAL_OUTPUT_EXAMPLE.md  Expected logs
â”œâ”€â”€ DEMO_GUIDE.md             Presentation guide
â””â”€â”€ VISUAL_FLOW.md            Architecture diagrams
```

---

## ğŸ¨ UI vs Terminal

### UI Shows (Clean & Simple):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Enter your question:           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ How will rate cut...?   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         [Ask]                   â”‚
â”‚                                 â”‚
â”‚  ğŸ’¡ Answer                      â”‚
â”‚  The RBI's 0.25% cut will...   â”‚
â”‚                                 â”‚
â”‚  ğŸ•¸ï¸ Knowledge Graph             â”‚
â”‚  Entities: RBI, Repo Rate...   â”‚
â”‚  Relations: RBI â†’ controls...  â”‚
â”‚                                 â”‚
â”‚  ğŸ“š Sources                     â”‚
â”‚  Home Loan.pdf (Page 1)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Terminal Shows (Verbose Processing):
```
=================================================
USER QUESTION: How will rate cut affect loans?
=================================================

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 1: QUERY ANALYSIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¯ Analyzing query type...
ğŸ”€ Hybrid mode enabled by default

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 2: VECTOR SEARCH PIPELINE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ğŸ”€ RAG FUSION - Query Generation:
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         Original query processed
         Variant 1 generated from original
         Variant 2 generated from original
         Variant 3 generated from original
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   ğŸ” Searching with 4 query variations...
      Query 1: Found 5 documents
      Query 2: Found 5 documents
      Query 3: Found 4 documents
      Query 4: Found 5 documents

   âœ… Fusion Complete:
      â€¢ Total unique chunks: 8
      â€¢ Top 5 selected
      â€¢ Fusion scores: [4, 3, 3, 2, 2]

   ğŸ”¬ CORRECTIVE RAG: Evaluating relevance...
      ğŸ”¬ Evaluating 8 documents for relevance...
         Doc 1: âœ“ Relevant
         Doc 2: âœ“ Relevant
         Doc 3: âœ“ Relevant
         Doc 4: âœ— Not relevant
         Doc 5: âœ“ Relevant
         Doc 6: âœ“ Relevant
         Doc 7: âœ— Not relevant
         Doc 8: âœ— Not relevant
   âœ… Refined from 8 to 5 relevant docs

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 3: GRAPH SEARCH PIPELINE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ•¸ï¸ Retrieving from knowledge graph...
âœ… Retrieved 8 entities, 6 relationships

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 4: CONTEXT COMBINATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”— Combining vector and graph contexts...
   â”œâ”€ Vector chunks: 5
   â”œâ”€ Graph entities: 8
   â””â”€ Graph relations: 6

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 5: ANSWER GENERATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Generated answer (247 words)

=================================================
âœ… QUERY PROCESSING COMPLETE
=================================================
```

---

## ğŸ“„ Supported File Types

### PDF Files
- âœ… Text-based PDFs (native text extraction)
- âœ… Scanned PDFs (OCR with Tesseract)
- âœ… Multi-page documents
- âœ… Automatic page tracking

### Image Files
- âœ… PNG, JPG, JPEG
- âœ… GIF, BMP, TIFF
- âœ… OCR text extraction
- âœ… Handles images without text

**Processing is identical for both - same workflow, same techniques!**

---

## âš™ï¸ Configuration

### Default Settings (config.py)

```python
class RAGConfig(BaseModel):
    # Models
    llm_model: str = "gpt-4o-mini"            # Answer generation
    embedding_model: str = "text-embedding-3-small"
    
    # Document Processing
    chunk_size: int = 1000                     # Characters per chunk
    chunk_overlap: int = 200                   # Overlap between chunks
    
    # Retrieval
    top_k_retrieval: int = 5                   # Documents to retrieve
    
    # RAG Techniques (all enabled by default)
    rag_fusion: bool = True                    # Multi-query generation
    adaptive_retrieval: bool = True            # Complexity-based
    corrective_rag: bool = True                # Relevance filtering
    use_knowledge_graph: bool = True           # Entity extraction
    use_hybrid_by_default: bool = True         # Always use both
    
    # Answer Generation
    llm_temperature: float = 0.1               # Deterministic
    # max_tokens: 1000 (set in hybrid_rag.py)
```

### Changing Settings

**Option 1: Edit config.py**
```python
class RAGConfig(BaseModel):
    chunk_size: int = 1500  # Larger chunks
    top_k_retrieval: int = 8  # More documents
```

**Option 2: Environment Variables**
```bash
export CHUNK_SIZE=1500
export TOP_K_RETRIEVAL=8
```

**No hardcoded values** - everything configurable!

---

## ğŸ¬ Demo Instructions

### Setup for Presentation

1. **Split Screen** - Terminal left, Browser right
2. **Increase Font** - Make terminal readable
3. **Prepare Documents** - Have PDF/image ready
4. **Test Run** - Verify everything works

### Demo Flow (5 minutes)

**Minute 1: Upload**
```bash
# Show terminal
streamlit run app_clean.py

# In UI: Upload "Home Loan.pdf" or any image
# Terminal shows: Processing, chunking, indexing
```

**Minute 2: Simple Question**
```
Question: "What is this document about?"
Terminal: Shows vector search, 3-5 chunks found
UI: Clean answer with sources
```

**Minute 3: Complex Question**
```
Question: "How are the entities connected?"
Terminal: Shows full hybrid flow:
  - RAG Fusion (4 variants created)
  - Vector search results
  - Corrective filtering
  - Graph entity extraction
  - Context combination
UI: Answer + Knowledge Graph insights
```

**Minute 4: Highlight Features**
```
Point to terminal:
  "See how it generates query variations"
  "Notice the relevance filtering"
  "Graph found these relationships"
  
Point to UI:
  "Clean answer under 1000 tokens"
  "Entities and relationships shown"
  "Sources are cited"
```

**Minute 5: Q&A**
```
Show configuration options
Demonstrate with different file types
Answer technical questions
```

---

## ğŸ”§ Technical Details

### Vector Search Pipeline

1. **Document Processing**
   - PDF: PyPDF2 or OCR
   - Image: Tesseract OCR
   - Chunking: 1000 chars, 200 overlap

2. **Embedding**
   - Model: text-embedding-3-small
   - Dimensions: 1536
   - Storage: ChromaDB

3. **RAG Techniques**
   - **Fusion**: 4 query variations
   - **Adaptive**: 3-8 docs based on complexity
   - **Corrective**: LLM relevance check

### Knowledge Graph Pipeline

1. **Entity Extraction**
   - LLM: GPT-4o-mini
   - Types: PERSON, ORG, LOCATION, CONCEPT, etc.
   - Properties: Extracted from context

2. **Relationship Extraction**
   - Types: WORKS_FOR, CONTROLS, AFFECTS, etc.
   - Properties: Context-dependent

3. **Graph Construction**
   - Library: NetworkX
   - Structure: MultiDiGraph
   - Querying: Subgraph traversal

### Hybrid Intelligence

1. **Query Analysis**
   - LLM determines: vector/graph/hybrid
   - Default: hybrid (both pipelines)

2. **Context Combination**
   - Vector: Relevant text chunks
   - Graph: Entities + relationships
   - Merged: Comprehensive context

3. **Answer Generation**
   - Model: GPT-4o-mini
   - Max tokens: 1000
   - Temperature: 0.1 (deterministic)

---

## ğŸ“Š Performance & Costs

### Processing Speed
| Operation | Time |
|-----------|------|
| PDF (10 pages) | 15-20 sec |
| Image (1 page) | 3-5 sec |
| Vector indexing | 2-3 sec |
| Graph building | 5-10 sec |
| Query processing | 4-6 sec |

### API Costs (GPT-4o-mini)
| Operation | Cost |
|-----------|------|
| Process 1 PDF | $0.01-0.02 |
| Process 1 Image | $0.005-0.01 |
| 1 Query | $0.001-0.002 |
| 100 Queries | $0.10-0.20 |
| Monthly (typical) | $5-20 |

---

## ğŸ› Troubleshooting

### Common Issues

**1. "Tesseract not found"**
```bash
# Install Tesseract OCR
sudo apt-get install tesseract-ocr  # Ubuntu
brew install tesseract              # macOS
# Windows: Download installer
```

**2. "OpenAI API Error"**
```bash
# Check API key
echo $OPENAI_API_KEY

# Verify billing at platform.openai.com
# Ensure you have credits
```

**3. "Processing is slow"**
```python
# Edit config.py
chunk_size: int = 800  # Smaller chunks
top_k_retrieval: int = 3  # Fewer docs
```

**4. "Out of memory"**
```bash
# Process fewer documents at once
# Close other applications
# Increase system RAM
```

**5. "Network error"**
```python
# Check internet connection
# Verify OpenAI API status
# Check firewall settings
```

---

## ğŸš€ Production Deployment

### Docker (Recommended)

```dockerfile
FROM python:3.9-slim

RUN apt-get update && apt-get install -y \
    tesseract-ocr poppler-utils \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

ENV OPENAI_API_KEY=""
EXPOSE 8501

CMD ["streamlit", "run", "app_clean.py", "--server.address", "0.0.0.0"]
```

```bash
docker build -t hybrid-rag .
docker run -p 8501:8501 -e OPENAI_API_KEY=sk-xxx hybrid-rag
```

### Cloud Platforms

**Streamlit Cloud:**
- Push to GitHub
- Deploy at share.streamlit.io
- Add secrets in dashboard

**AWS EC2:**
- t3.medium or larger
- Install dependencies
- Use systemd service

**Google Cloud Run:**
- Build container
- Deploy with API key as env var

---

## ğŸ“š Additional Documentation

- **SETUP.md** - Detailed setup instructions
- **DEMO_GUIDE.md** - Complete demo script
- **VISUAL_FLOW.md** - Architecture diagrams
- **TERMINAL_OUTPUT_EXAMPLE.md** - Expected logs
- **CLEAN_UI_README.md** - Feature overview

---

## ğŸ¯ Key Advantages

1. **Dual Intelligence** - Vector + Graph combined
2. **Advanced RAG** - Fusion, Adaptive, Corrective
3. **Clean UI** - User-friendly interface
4. **Verbose Logging** - Developer-friendly terminal
5. **File Agnostic** - Same workflow for PDF/images
6. **Production Ready** - Error handling, logging, testing
7. **Cost Effective** - GPT-4o-mini (~$0.01/document)
8. **Fully Configurable** - No hardcoded values

---

## ğŸ“ Support

- **Issues:** Check TERMINAL_OUTPUT_EXAMPLE.md
- **Questions:** See DEMO_GUIDE.md
- **Configuration:** Edit config.py
- **Deployment:** See above section

---

## ğŸ“ License

Open source - Available for educational and commercial use.

---

**Built with â¤ï¸ using LangChain, OpenAI, Streamlit, and NetworkX**

*Last updated: February 2026*
